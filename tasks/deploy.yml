---
# tasks for deploy cluster

- name: ({{ cluster_name }}) Set tag variable
  ansible.builtin.set_fact:
    tag: 'deploy'
    first_deploy: true

- name: ({{ cluster_name }}) Check admin password is defined
  ansible.builtin.fail:
    msg: 'Ошибка! Пароль администратора должен быть определен (admin_password)!'
  when: admin_password is undefined
  run_once: true
  delegate_to: localhost

- name: ({{ cluster_name }}) Set listen address for every host
  ansible.builtin.set_fact:
    listen_address: "{{ listen_address }}"
  when: hostvars[inventory_hostname]['listen_address'] is undefined

- name: ({{ cluster_name }}) Check picodata is installed
  ansible.builtin.stat:
    path: '{{ bin_dir }}/picodata'
  register: result

- name: ({{ cluster_name }}) Set flag for install picodata needed
  ansible.builtin.set_fact:
    install_packages: '{{ not result.stat.exists }}'

- name: ({{ cluster_name }}) Need to install Picodata package
  ansible.builtin.fail:
    msg: 'Ошибка! На серверах кластера необходимо установить пакет picodata!'
  when: install_packages == true and rootless == true
  run_once: true
  delegate_to: localhost

- name: ({{ cluster_name }}) Set flag for skip check install tasks
  ansible.builtin.set_fact:
    skip_check_install: true

- name: ({{ cluster_name }}) Deploy tasks for become
  ansible.builtin.include_tasks:
    file: deploy_become.yml
  when: rootless == false

- name: ({{ cluster_name }}) Get version of picodata from shell
  ansible.builtin.shell:
    cmd: 'picodata -V |head -1 | cut -f 1 -d "," | cut -f 2 -d " "'
  register: result
  changed_when: false

- name: ({{ cluster_name }}) Put version of picodata in var
  ansible.builtin.set_fact:
    picodata_version: '{{ result.stdout }}'

- name: ({{ cluster_name }}) Debug picodata_version
  ansible.builtin.debug:
    var: picodata_version
  when: debug == true

- name: ({{ cluster_name }}) Create dirs with cluster-name
  ansible.builtin.file:
    name: '{{ item }}'
    state: directory
    owner: '{{ user }}'
    group: '{{ group }}'
    mode: '{{ dir_mode }}'
  loop:
    - '{{ conf_dir }}/{{ cluster_name }}'
    - '{{ log_dir }}/{{ cluster_name }}'
    - '{{ data_dir }}/{{ cluster_name }}'
    - '{{ share_dir }}/{{ cluster_name }}'
    - '{{ run_dir }}/{{ cluster_name }}'
    - '{{ cert_dir }}/{{ cluster_name }}'
    - '{{ cert_dir }}/{{ cluster_name }}/pg'
    - '{{ cert_dir }}/{{ cluster_name }}/iproto'

- name: ({{ cluster_name }}) Create dirs for crash_dumps
  ansible.builtin.file:
    name: '{{ item }}'
    state: directory
    owner: '{{ user }}'
    group: '{{ group }}'
    mode: '0755'
  loop:
    - '{{ backup_dir }}/{{ cluster_name }}/crash_dumps'

- name: ({{ cluster_name }}) Create dirs for cluster for rootless
  become_user: '{{ systemd_user }}'
  ansible.builtin.file:
    name: '{{ item }}'
    state: directory
  loop:
    - '{{ systemd_dir }}'
  when: systemd_scope == 'user'

- block:
  - name: ({{ cluster_name }}) Create dirs for supervisord
    ansible.builtin.file:
      name: '{{ item }}'
      state: directory
      owner: '{{ user }}'
      group: '{{ group }}'
      mode: '{{ dir_mode }}'
    loop:
      - '{{ supervisord_dir }}/{{ cluster_name }}'

  - name: ({{ cluster_name }}) Generate service unit for supervisord
    ansible.builtin.template:
      src: supervisord-unit-service.j2
      dest: '{{ systemd_dir }}/supervisord-{{ cluster_name }}.service'

  - name: ({{ cluster_name }}) Generate cluster config file for supervisord
    ansible.builtin.template:
      src: supervisord-conf.j2
      dest: '{{ supervisord_dir }}/{{ cluster_name }}.conf'
    notify:
      - restart

  - name: ({{ cluster_name }}) Enable systemd service for supervisord
    ansible.builtin.systemd:
      name: 'supervisord-{{ cluster_name }}.service'
      enabled: true
      state: started
      daemon_reload: true
      scope: '{{ systemd_scope }}'
    register: supervisord_service
    environment:
      XDG_RUNTIME_DIR: /run/user/{{uid.stdout}}

  - name: ({{ cluster_name }}) Check restart if needed
    ansible.builtin.set_fact:
      need_restart: false
    when: supervisord_service.changed == true

  when: init_system == 'supervisord' and systemd_scope == 'user'

- name: ({{ cluster_name }}) Merge systemd params
  ansible.builtin.set_fact:
    systemd_params: '{{ systemd_params_default | ansible.builtin.combine(systemd_params|default({})) }}'
  run_once: true

- name: ({{ cluster_name }}) Debug systemd_params
  ansible.builtin.debug:
    var: systemd_params
  run_once: true
  when: debug == true

- name: ({{ cluster_name }}) Generate template file for systemd
  become: true
  become_user: '{{ systemd_user }}'
  ansible.builtin.template:
    src: systemd-unit-service.j2
    dest: '{{ systemd_dir }}/{{ cluster_name }}@.service'
    force: true
  when: init_system == 'systemd' and autonames|bool == false
  notify:
    - restart

- name: ({{ cluster_name }}) Debug db_config
  debug:
    var: db_config
  run_once: true
  when: debug == true

- name: ({{ cluster_name }}) init db_config_all
  ansible.builtin.set_fact:
    db_config_all: ""

- name: ({{ cluster_name }}) Fill db_config_all with parameters
  ansible.builtin.set_fact:
    db_config_all: |
      {% for key, value in db_config.items() %}
      alter system set "{{ key }}" = {{ value }} for all tiers;
      {% endfor %}
  when: db_config is defined

- name: ({{ cluster_name }}) Debug all host group
  debug:
    msg: "tiers_host_groups: {{ all_host_groups }}"
  run_once: true
  when: debug == true

# default добавлены для совместимости с предыдущей версией
# TODO убрать default в 26.1
- name: ({{ cluster_name }}) Copy certs for PG
  become: true
  ansible.builtin.copy:
    src: '{{ item.filename }}'
    dest: '{{ cert_dir }}/{{ cluster_name }}/pg'
    mode: '{{ item.mode }}'
  loop:
    - { filename: '{{ pg_cert_file | default(cert_file) }}', mode: '0644' }
    - { filename: '{{ pg_key_file | default(key_file) }}', mode: '0640' }
    - { filename: '{{ pg_ca_file | default(ca_file) }}', mode: '0644' }
  when: pg_ssl == true

- name: ({{ cluster_name }}) Copy certs for iproto
  become: true
  ansible.builtin.copy:
    src: '{{ item.filename }}'
    dest: '{{ cert_dir }}/{{ cluster_name }}/iproto/'
    mode: '{{ item.mode }}'
  loop:
    - { filename: '{{ iproto_cert_file }}', mode: '0644' }
    - { filename: '{{ iproto_key_file }}', mode: '0640' }
    - { filename: '{{ iproto_ca_file }}', mode: '0644' }
  when: iproto_tls == true

- name: ({{ cluster_name }}) Generate list of instances per server
  ansible.builtin.include_tasks:
    file: genin.yml

- block:
  - name: ({{ cluster_name }}) Set actual failure domain
    ansible.builtin.set_fact:
      fd: '"G":"{{ group_names }}","H":"{{ inventory_hostname }}"'
    when: ver_fd|int | default(2) == 2

  - name: ({{ cluster_name }}) Set failure domain for previous version
    ansible.builtin.set_fact:
      fd: '"DC":"{{ group_names }}","HOST":"{{ inventory_hostname }}"'
    when: ver_fd|int | default(2) == 1

  - name: ({{ cluster_name }}) Debug failure domain
    ansible.builtin.debug:
      msg: 'fd is {{ fd }}'

  when: not fd_uniq_per_instance
# end block

- name: Reset failed systemd service
  ansible.builtin.command:
    cmd: 'systemctl reset-failed --{{ systemd_scope }} {{ cluster_name }}* --all'
  environment:
    XDG_RUNTIME_DIR: /run/user/{{uid.stdout}}
  changed_when: false
  when: init_system == 'systemd' and real_cnt|int > 0

- name: ({{ cluster_name }}) Init start values
  ansible.builtin.set_fact:
    cnt: 0

- name: ({{ cluster_name }}) Tiers setup
  ansible.builtin.include_tasks:
    file: tiers_setup.yml
  loop: "{{ lookup('ansible.builtin.dict', tiers, wantlist=True) }}"
  loop_control:
    loop_var: tier
    extended: true

- name: ({{ cluster_name }}) Update cluster in supervisord
  ansible.builtin.command:
    cmd: '/usr/bin/supervisorctl -c {{ supervisord_dir }}/{{ cluster_name }}.conf update'
  register: supervisord_update
  when: init_system == 'supervisord'
  changed_when: false

- name: ({{ cluster_name }}) Wait creating admin-sock files for all instances
  ansible.builtin.wait_for:
    path: '{{ run_dir }}/{{ cluster_name }}/{{ item }}.sock'
    state: present
    msg: 'Ошибка ожидания сокет-файла: {{ run_dir }}/{{ cluster_name }}/{{ item }}.sock! Проверьте логи инстанса!'
    timeout: '{{ timeout_admin_sock }}'
  retries: '{{ retries_admin_sock }}'
  loop: '{{ instances_on_host }}'

- name: ({{ cluster_name }}) Debug db_config_all
  debug:
    var: db_config_all
  run_once: true
  when: debug == true

- name: ({{ cluster_name }}) Generate sql-file for db_config
  ansible.builtin.copy:
    content: '{{ db_config_all }}'
    dest: '{{ conf_dir }}/{{ cluster_name }}/dbconfig.sql'
  run_once: true
  when: db_config_all != ""
  notify:
    - apply_db_config

- name: ({{ cluster_name }}) Set admin password
  ansible.builtin.shell:
    cmd: >
         echo "
         ALTER USER \"admin\" password '{{ admin_password }}' USING md5;
         ALTER USER \"admin\" WITH LOGIN;
         " | {{ bin_dir }}/picodata admin {{ run_dir }}/{{ cluster_name }}/{{ instances_on_host[0] }}.sock
  register: cluster_status
  until: cluster_status.rc == 0
  retries: 3
  delay: 5
  run_once: true

- name: ({{ cluster_name }}) Setup auth in WebUI
  ansible.builtin.shell:
    cmd: >
         echo "
         ALTER SYSTEM RESET jwt_secret;
         {% if auth_webui == false %}
         ALTER SYSTEM SET jwt_secret = '';
         {% endif %}
         " | {{ bin_dir }}/picodata admin {{ run_dir }}/{{ cluster_name }}/{{ instances_on_host[0] }}.sock
  register: cluster_status
  until: cluster_status.rc == 0
  retries: 3
  delay: 5
  run_once: true
  when: auth_webui is defined

- name: ({{ cluster_name }}) Copy sql-file on server
  ansible.builtin.copy:
    src: '{{ sql_file }}'
    dest: '{{ conf_dir }}/{{ cluster_name }}/after_deploy.sql'
  run_once: true
  when: sql_file is defined
  notify:
    - apply_sql_file

# не рестартуем кластер, если это его первый деплой
- name: ({{ cluster_name }}) Check restart if needed for first deploy
  ansible.builtin.set_fact:
    need_restart: false
  when: first_deploy == true

# создаем ссылки на инстансы кластера, если это его первый деплой
- name: Make links for instance name
  ansible.builtin.include_tasks:
    file: make_links.yml
  when: autonames|bool == true and first_deploy == true and "restore_full" not in ansible_run_tags

- name: ({{ cluster_name }}) Install plugins
  ansible.builtin.include_tasks:
    file: plugins.yml
  when: plugins is defined

- name: ({{ cluster_name }}) Print instances on hosts
  ansible.builtin.debug:
    var: list_instance_names | default(instances_on_host)
